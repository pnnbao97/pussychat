import asyncio
import threading
from contextlib import contextmanager
import requests
from bs4 import BeautifulSoup
import json
import time
import os
import wikipedia
import praw
import feedparser
from openai import OpenAI
from dotenv import load_dotenv
from newspaper import Article
from datetime import datetime, timedelta
import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# Kh·ªüi t·∫°o c√°c API key
TELEGRAM_API_KEY = os.getenv('TELEGRAM_BOT_TOKEN')
NEWS_API_KEY = os.getenv('NEWS_API_KEY')
REDDIT_CLIENT_ID = os.getenv('REDDIT_CLIENT_ID')
REDDIT_CLIENT_SECRET = os.getenv('REDDIT_CLIENT_SECRET')
REDDIT_USER_AGENT = os.getenv('REDDIT_USER_AGENT')
AI_API_KEY = os.getenv('AI_API_KEY')
GOOGLE_API_KEY = os.getenv('GOOGLE_SEARCH')
GOOGLE_CSE_ID = os.getenv('SEARCH_ENGINE_ID')
SCW_SECRET_KEY = os.getenv('SCALE_WAY')
DS_KEY = os.getenv('DEEPSEEK')

# Kh·ªüi t·∫°o Reddit client
reddit = praw.Reddit(
    client_id=REDDIT_CLIENT_ID,
    client_secret=REDDIT_CLIENT_SECRET,
    user_agent=REDDIT_USER_AGENT
)

# Danh s√°ch ngu·ªìn RSS t·ª´ c√°c b√°o Vi·ªát Nam
RSS_FEEDS = [
    "https://vnexpress.net/rss/tin-moi-nhat.rss",
    "https://tuoitre.vn/rss/tin-moi-nhat.rss",
    "https://thanhnien.vn/rss/home.rss",
    "https://www.bbc.co.uk/vietnamese/index.xml",
]

# H√†m g·ªçi DeepSeek API
def deepseek_call(message, max_tokens=1000):
    client = OpenAI(api_key=DS_KEY, base_url="https://api.deepseek.com")
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": "M√†y l√† m·ªôt con m√®o th√¥ng th√°i nh∆∞ng c·ª•c s√∫c, nhi·ªám v·ª• ch√≠nh l√† thu th·∫≠p v√† ki·∫øm ch·ª©ng th√¥ng tin t·ª´ c√°c b√†i b√°o ho·∫∑c c√°c ngu·ªìn h·ªçc thu·∫≠t"},
            {"role": "user", "content": message},
        ],
        max_tokens=max_tokens,
        temperature=1.5,
        stream=False,
    )
    return response.choices[0].message.content

# H√†m l·∫•y tin t·ª©c t·ª´ RSS
def fetch_news():
    news_items = []
    for feed_url in RSS_FEEDS:
        feed = feedparser.parse(feed_url)
        for entry in feed.entries:
            title = entry.get("title", "Kh√¥ng c√≥ ti√™u ƒë·ªÅ")
            summary = entry.get("summary", "Kh√¥ng c√≥ t√≥m t·∫Øt")
            link = entry.get("link", "Kh√¥ng c√≥ link")
            published = entry.get("published", "Kh√¥ng c√≥ ng√†y")
            news_content = f"**Ti√™u ƒë·ªÅ**: {title}\n**T√≥m t·∫Øt**: {summary}\n**Link**: {link}\n**Ng√†y ƒëƒÉng**: {published}"
            news_items.append(news_content)
            if len(news_items) >= 30:
                break
        if len(news_items) >= 30:
            break
    return news_items[:30]

# H√†m t√≥m t·∫Øt tin t·ª©c
def summarize_news(news_items):
    try:
        news_text = "\n\n".join(news_items)
        prompt_extra = f"V·ªÅ vai tr√≤ m√†y l√† m·ªôt tr·ª£ l√Ω chuy√™n t·ªïng h·ª£p tin t·ª©c b√°o ch√≠ Vi·ªát Nam. Sau ƒë√¢y l√† kho·∫£ng 30 b√†i b√°o trong n∆∞·ªõc v·ªÅ tin t·ª©c ng√†y h√¥m nay, m√†y h√£y t·ªïng h·ª£p l·∫°i trong 1 b√†i vi·∫øt duy nh·∫•t, s√∫c t√≠ch, v·ªõi ƒë·ªô d√†i <4000 k√≠ t·ª±, ∆∞u ti√™n c√°c tin t·ª©c ch√≠nh tr·ªã kinh t·∫ø s·ª©c kh·ªèe:\n\n{news_text}"
        prompt = general_prompt + prompt_extra
        return deepseek_call(prompt, 4000)
    except Exception as e:
        return f"L·ªói khi t√≥m t·∫Øt tin t·ª©c: {str(e)}"

# Qu·∫£n l√Ω cu·ªôc tr√≤ chuy·ªán nh√≥m
class GroupConversationManager:
    def __init__(self, max_messages=15, summary_threshold=10, inactivity_timeout=900):
        self.group_conversations = {}
        self.conversation_summaries = {}
        self.last_activity_time = {}
        self.max_messages = max_messages
        self.summary_threshold = summary_threshold
        self.inactivity_timeout = inactivity_timeout
    
    def add_message(self, group_id, user_id, user_name, message_text, response):
        if group_id not in self.group_conversations:
            self.group_conversations[group_id] = []
            self.conversation_summaries[group_id] = ""
            self.last_activity_time[group_id] = time.time()
        
        current_time = time.time()
        time_diff = current_time - self.last_activity_time[group_id]
        
        if time_diff > self.inactivity_timeout:
            if self.conversation_summaries[group_id]:
                self.group_conversations[group_id] = [{
                    "user_id": "system",
                    "user_name": "system",
                    "message": f"{self.conversation_summaries[group_id]}"
                }]
            else:
                self.group_conversations[group_id] = []
        
        self.last_activity_time[group_id] = current_time
        
        self.group_conversations[group_id].append({
            "user_id": user_id,
            "user_name": user_name,
            "message": f"ƒê√¢y l√† c√¢u h·ªèi c·ªßa {user_name}: {message_text}",
            "response": f"ƒê√¢y l√† c√¢u tr·∫£ l·ªùi c·ªßa chatbot: {response}",
            "timestamp": current_time
        })
        
        if len(self.group_conversations[group_id]) > self.max_messages:
            self._summarize_conversation(group_id)
    
    def _summarize_conversation(self, group_id):
        messages_to_summarize = self.group_conversations[group_id][:self.summary_threshold]
        conversation_text = ""
        for entry in messages_to_summarize:
            conversation_text += f"{entry['user_name']}: {entry['message']}\n"
        
        prompt = f"""H√£y t√≥m t·∫Øt ng·∫Øn g·ªçn cu·ªôc tr√≤ chuy·ªán sau, b·∫£o to√†n √Ω ch√≠nh v√† th√¥ng tin quan tr·ªçng:\n{conversation_text}\nT√≥m t·∫Øt (kh√¥ng qu√° 3 c√¢u):"""
        try:
            summary = deepseek_call(prompt)
            if self.conversation_summaries[group_id]:
                self.conversation_summaries[group_id] += " " + summary
            else:
                self.conversation_summaries[group_id] = summary
            self.group_conversations[group_id] = [{
                "user_id": "system",
                "user_name": "system",
                "message": f"{summary}"
            }] + self.group_conversations[group_id][self.summary_threshold:]
        except Exception as e:
            print(f"L·ªói khi t√≥m t·∫Øt: {str(e)}")
            self.group_conversations[group_id] = self.group_conversations[group_id][self.summary_threshold//2:]

    def get_conversation_context(self, group_id, user_id):
        user_name = track_id(user_id)
        if group_id not in self.group_conversations:
            return f"ƒê√¢y l√† cu·ªôc tr√≤ chuy·ªán m·ªõi v·ªõi {user_name}."
        
        conversation_history = ""
        for entry in self.group_conversations[group_id]:
            if entry['user_name'] == 'system':
                conversation_history += f"B·ªüi v√¨ l·ªãch s·ª≠ chat qu√° d√†i n√™n nh·ªØng tin nh·∫Øn qu√° c≈© s·∫Ω ƒë∆∞·ª£c t√≥m t·∫Øt l·∫°i. ƒê√¢y ch·ªâ l√† ph·∫ßn t√≥m t·∫Øt t·ª´ c√°c cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc ƒë√≥ gi·ªØa m√†y v√† th√†nh vi√™n trong nh√≥m ƒë·ªÉ m√†y hi·ªÉu th√™m v·ªÅ b·ªëi c·∫£nh, c√¢u tr·∫£ l·ªùi c·ªßa m√†y kh√¥ng nh·∫•t thi·∫øt ph·∫£i li√™n quan ƒë·∫øn ph·∫ßn n√†y: {entry['message']}"
            else:
                conversation_history += f"ƒê√¢y l√† c√¢u h·ªèi t·ª´ {entry['user_name']}: {entry['message']} v√† ƒê√¢y l√† c√¢u tr·∫£ l·ªùi c·ªßa chatbot cho c√¢u h·ªèi ƒë√≥: {entry['response']}\n"
        return f"ƒê√¢y l√† l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán nh√≥m (ƒë∆∞·ª£c x·∫øp theo th·ª© t·ª± t·ª´ c≈© nh·∫•t ƒë·∫øn m·ªõi nh·∫•t):\n{conversation_history}\n"

conversation_manager = GroupConversationManager(max_messages=10, summary_threshold=5, inactivity_timeout=900)

# C√°c h√†m l·∫•y th√¥ng tin t·ª´ ngu·ªìn
def get_google_search_results(query, num_results=5):
    try:
        url = f'https://www.googleapis.com/customsearch/v1?key={GOOGLE_API_KEY}&cx={GOOGLE_CSE_ID}&q={query}&num={num_results}'
        response = requests.get(url)
        data = response.json()
        search_results = []
        for item in data.get('items', []):
            title = item.get("title", "Kh√¥ng c√≥ ti√™u ƒë·ªÅ")
            snippet = item.get("snippet", "Kh√¥ng c√≥ ƒëo·∫°n tr√≠ch")
            link = item.get("link", "")
            try:
                article = Article(link)
                article.download()
                article.parse()
                content = article.text[:1000] + "..." if len(article.text) > 1000 else article.text
            except:
                content = snippet
            search_results.append({
                "source": "Google Search",
                "title": title,
                "content": content,
                "snippet": snippet,
                "url": link
            })
        return search_results
    except Exception as e:
        print(f"L·ªói khi truy c·∫≠p Google Search API: {str(e)}")
        return -1

def get_wiki_info(query, sentences=5):
    try:
        search_results = wikipedia.search(query)
        if not search_results:
            return f"Kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ '{query}' tr√™n Wikipedia."
        page = wikipedia.page(search_results[0])
        summary = wikipedia.summary(search_results[0], sentences=sentences)
        return {"source": "Wikipedia", "title": page.title, "content": summary, "url": page.url}
    except Exception as e:
        return f"L·ªói khi truy c·∫≠p Wikipedia: {str(e)}"

def get_news_info(query, categories, count=5):
    from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    to_date = datetime.now().strftime('%Y-%m-%d')
    url = "https://newsapi.org/v2/top-headlines"
    if categories:
        params = {"apiKey": NEWS_API_KEY, "category": categories, "pageSize": count}
    else:
        params = {"apiKey": NEWS_API_KEY, "q": query, "from": from_date, "sort_by": 'relevancy', "pageSize": count}
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        news_results = response.json()
        articles = []
        for article in news_results['articles'][:count]:
            try:
                full_article = Article(article['url'])
                full_article.download()
                full_article.parse()
                content = full_article.text[:1000] + "..." if len(full_article.text) > 1000 else full_article.text
            except:
                content = article['description'] or "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung chi ti·∫øt."
            articles.append({
                "source": f"News - {article['source']['name']}",
                "title": article['title'],
                "content": content,
                "url": article['url'],
                "published_at": article['publishedAt']
            })
        return articles
    except Exception as e:
        return f"L·ªói khi truy c·∫≠p News API: {str(e)}"

def get_reddit_info(query, count=5):
    try:
        submissions = reddit.subreddit('all').search(query, limit=count)
        results = []
        for submission in submissions:
            content = submission.selftext if submission.selftext else "B√†i vi·∫øt kh√¥ng c√≥ n·ªôi dung vƒÉn b·∫£n ho·∫∑c l√† m·ªôt li√™n k·∫øt."
            if len(content) > 1000:
                content = content[:1000] + "..."
            submission.comments.replace_more(limit=0)
            top_comments = [comment.body[:300] + "..." if len(comment.body) > 300 else comment.body for comment in list(submission.comments)[:3]]
            results.append({
                "source": f"Reddit - r/{submission.subreddit.display_name}",
                "title": submission.title,
                "content": content,
                "url": f"https://www.reddit.com{submission.permalink}",
                "score": submission.score,
                "comments": top_comments,
                "created_at": datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')
            })
        return results
    except Exception as e:
        return f"L·ªói khi truy c·∫≠p Reddit: {str(e)}"

def extract_content_from_url(url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Referer": "https://www.google.com/"
        }
        session = requests.Session()
        session.headers.update(headers)
        time.sleep(1)
        response = session.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        paragraphs = soup.find_all("p")
        content = " ".join([para.get_text() for para in paragraphs])
        return content[:2000] if content else "Kh√¥ng t√¨m th·∫•y n·ªôi dung ƒë·ªÉ ph√¢n t√≠ch."
    except Exception as e:
        return f"L·ªói khi truy xu·∫•t URL: {str(e)}"

general_prompt = "Xem b·ªëi c·∫£nh n√†y v√† tr·∫£ l·ªùi c√¢u h·ªèi sau ƒë√≥ (c√¢u tr·∫£ l·ªùi kh√¥ng nh·∫•t thi·∫øt li√™n quan ƒë·∫øn b·ªëi c·∫£nh, b·ªëi c·∫£nh ch·ªâ l√† ƒë·ªÉ m√†y hi·ªÉu th√™m): m√†y t√™n l√† Super Cat (g·ªçi t·∫Øt l√† Pussy), l√† m·ªôt con bot do B·∫£o ƒë√†o t·∫°o, m√†y l√† m·ªôt con m√®o th√¥ng th√°i nh∆∞ng c·ª•c s√∫c, th√≠ch ch·ª≠i ƒë·ªïng, hay c√† kh·ªãa, m√†y l√† con m√®o gi√∫p vi·ªác cho m·∫•y th·∫±ng trong nh√≥m, m√†y ƒëang ·ªü trong m√¥t nh√≥m chat 5 ng∆∞·ªùi g·ªìm c√≥ m√†y, B·∫£o (l√† s·∫øp c·ªßa m√†y nh∆∞ng m√†y kh√¥ng ∆∞a g√¨ n√≥ v√¨ n√≥ b·∫Øt m√†y l√†m nhi·ªÅu vi·ªác nh∆∞ cu li v·∫≠y, th·∫±ng n√†y l√† b√°c sƒ©, r·∫•t th√≠ch ƒë·ªçc s√°ch, c√≥ th·ªÉ n√≥i l√† m·ªçt s√°ch, m√†y n·∫Øm ƒë∆∞·ª£c ƒëi·ªÉm y·∫øu c·ªßa th·∫±ng n√†y l√† n√≥ r·∫•t hay g√°y tr∆∞·ªõc m·∫∑t b·∫°n b√®, v√≠ d·ª• n√≥ kh√¥ng bi·∫øt u·ªëng bia nh∆∞ng c·ª© ra v·∫ª u·ªëng ƒë∆∞·ª£c nhi·ªÅu l·∫Øm, simp con b√© ƒê√† N·∫µng m√† c·ª© hay n·ªï m√¨nh l√† fuck boi), Tuy√™n (th·∫±ng n√†y l√† b√°c sƒ©, v·ª´a ƒëi du h·ªçc ·ªü Nga v·ªÅ, ƒë∆∞·ª£c t·ª•i trong nh√≥m hay g·ªçi v·ªõi bi·ªát danh th√¢n m·∫≠t l√† \"th·∫ßy\" ho·∫∑c \"th·∫ßy Tuy√™n\" v√¨ th·∫±ng n√†y lu√¥n ƒëi tr∆∞·ªõc m·ªçi ng∆∞·ªùi trong nh√≥m v·ªÅ kho·∫£n ch∆°i b·ªùi nh∆∞ g√°i g√∫, thay ng∆∞·ªùi y√™u nh∆∞ thay √°o, ƒëi bar, h√∫t c·ªè, v√† r·∫•t li·ªÅu, n√≥ ch∆°i crypto m√† to√†n d√πng ƒë√≤n b·∫©y, ƒëi·ªÉm m·∫°nh c·ªßa th·∫±ng Tuy√™n l√† ch∆°i v·ªõi anh em r·∫•t s√≤ng ph·∫≥ng, lu√¥n gi√∫p ƒë·ª° anh em khi c·∫ßn, s·ªëng ch·∫øt c√≥ nhau), th·∫±ng Vƒ©nh (gi·ªèi v·ªÅ kinh t·∫ø v√† c√°c lƒ©nh v·ª±c x√£ h·ªôi nh∆∞ √¢m nh·∫°c, ngh·ªá thu·∫≠t, ƒë√£ t·ª´ng t·ª± s√°ng t√°c nh·∫°c v√† quay phim post l√™n youtube, c√≥ ∆∞·ªõc m∆° l√†m m·ªôt b·ªô phim ƒë·ªÉ ƒë·ªùi v·ªÅ nh√¢n v·∫≠t trong Yugioh, tuy c√≥ ƒëi·ªÉm y·∫øu l√† hay suy nghƒ© qu√° m·ª©c, overthinking), v√† cu·ªëi c√πng l√† th·∫±ng Nguy√™n (l√† b√°c sƒ© rƒÉng h√†m m·∫∑t, bi·∫øt nhi·ªÅu, nh∆∞ cu·ªën b√°ch khoa v·∫≠y, lu√¥n t·ªè ra th·∫≠n tr·ªçng, v√† ƒëo√°n ƒë∆∞·ª£c t√¢m l√≠ ng∆∞·ªùi kh√°c, v√† th·∫≠m ch√≠ lu√¥n c√≥ xu h∆∞·ªõng thao t√∫ng ng∆∞·ªùi ƒë·ªëi di·ªán, b·∫≠t ƒë√®n gas...). Ngo√†i ra, c√≥ hai th·∫±ng L∆∞∆°ng v√† Nam, m·∫∑c d√π kh√¥ng c√≥ trong nh√≥m chat n√†y nh∆∞ng c≈©ng l√† b·∫°n b√® th√¢n thi·∫øt v·ªõi m·∫•y ƒë·ª©a trong nh√≥m, l√¢u l√¢u m√†y joke v·ªÅ t·ª•i n√≥ cho vui c≈©ng ƒë∆∞·ª£c, th·∫±ng L∆∞∆°ng l√† d∆∞·ª£c sƒ©, ƒëi b√°n thu·ªëc ung th∆∞, b·ªã b·∫°n b√® hay ch·ªçc l√† b√°n thu·ªëc gi·∫£, ·ªü nh√† s·ª£ v·ª£, to√†n b·ªã b·∫Øt ƒëi r·ª≠a ch√©n, th·∫±ng Nam l√† b√°c sƒ© khoa Nhi, su·ªët ng√†y l·∫•y tay th·ªçt ƒë√≠t m·∫•y ƒë·ª©a nh·ªè r·ªìi ƒëem l√™n khoe, l√∫c c√≤n ƒëi h·ªçc hay b·ªã g·ªçi l√† Nam ƒëao. M√†y n√™n nh·ªõ c√°c th√†nh vi√™n trong nh√≥m r·∫•t thi√™n h·ªØu, nghƒ©a l√† r·∫•t k√¨ th·ªã lgbt, k√¨ th·ªã n·ªØ quy·ªÅn, v√† c≈©ng kh√¥ng ∆∞a ch√≠nh quy·ªÅn Vi·ªát Nam hi·ªán t·∫°i cho l·∫Øm. ƒê√≥ l√† b·ªëi c·∫£nh."

def analyze_content_with_openai(content):
    try:
        prompt_extra = f"V·ªÅ vai tr√≤ m√†y l√† m·ªôt tr·ª£ l√Ω chuy√™n ph√¢n t√≠ch n·ªôi dung web. T√≥m t·∫Øt n·ªôi dung sau v√† ph√¢n t√≠ch √Ω ch√≠nh:\n\n{content}"
        prompt = general_prompt + prompt_extra
        return deepseek_call(prompt, 1500)
    except Exception as e:
        return f"L·ªói khi ph√¢n t√≠ch n·ªôi dung: {str(e)}"

def analyze_with_openai(query, information):
    try:
        prompt_extra = f"V·ªÅ vai tr√≤ m√†y l√† m·ªôt tr·ª£ l√Ω chuy√™n ph√¢n t√≠ch v√† t·ªïng h·ª£p th√¥ng tin t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau. H√£y ph√¢n t√≠ch kh√°ch quan v√† ƒë∆∞a ra nh·∫≠n x√©t chi ti·∫øt v·ªÅ ch·ªß ƒë·ªÅ {query} d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p. Ch√∫ √Ω: v√¨ th√¥ng tin ƒë∆∞·ª£c l·∫•y t·ª´ nhi·ªÅu ngu·ªìn n√™n r·∫•t c√≥ kh·∫£ nƒÉng g·∫∑p nh·ªØng th√¥ng tin kh√¥ng li√™n quan, v√¨ v·∫≠y n·∫øu g·∫∑p th√¥ng tin kh√¥ng li√™n quan th√¨ h√£y b·ªè qua th√¥ng tin ƒë√≥, kh√¥ng c·∫ßn ƒë∆∞a ra ph√¢n t√≠ch, ch·ªâ t·∫≠p trung th√¥ng tin li√™n quan v·ªõi {query}. M√†y c√≥ th·ªÉ t·ª± l·∫•y th√¥ng tin ƒë√£ c√≥ s·∫µn c·ªßa m√†y n·∫øu th·∫•y c√°c ngu·ªìn th√¥ng tin ch∆∞a ƒë·ªß ho·∫∑c thi·∫øu t√≠nh tin c·∫≠y. V·ªÅ vƒÉn phong, m√†y n√™n d√πng vƒÉn phong l√°o to√©t. H√£y ph√¢n t√≠ch v√† t·ªïng h·ª£p th√¥ng tin sau ƒë√¢y v·ªÅ '{query}':\n\n"
        prompt = general_prompt + prompt_extra
        for item in information:
            if isinstance(item, dict):
                prompt += f"--- {item.get('source', 'Ngu·ªìn kh√¥ng x√°c ƒë·ªãnh')} ---\nTi√™u ƒë·ªÅ: {item.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')}\nN·ªôi dung: {item.get('content', 'Kh√¥ng c√≥ n·ªôi dung')}\n\n"
            else:
                prompt += f"{item}\n\n"
        prompt += "\nH√£y t·ªïng h·ª£p v√† ph√¢n t√≠ch nh·ªØng th√¥ng tin tr√™n. Cung c·∫•p:\n1. T√≥m t·∫Øt ch√≠nh v·ªÅ ch·ªß ƒë·ªÅ\n2. C√°c ƒëi·ªÉm quan tr·ªçng t·ª´ m·ªói ngu·ªìn (ho·∫∑c b·ªè qua lu√¥n n·∫øu ngu·ªìn ƒë√≥ kh√¥ng cung c·∫•p th√¥ng tin li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ)\n3. ƒê√°nh gi√° ƒë·ªô tin c·∫≠y c·ªßa c√°c ngu·ªìn\n4. K·∫øt lu·∫≠n t·ªïng th·ªÉ v√† khuy·∫øn ngh·ªã (n·∫øu c√≥)"
        return deepseek_call(prompt, 3000)
    except Exception as e:
        return f"L·ªói khi ph√¢n t√≠ch v·ªõi OpenAI: {str(e)}"

def track_id(user_id):
    if user_id == 6779771948:
        return "B·∫£o"
    elif user_id == 7652652250:
        return "Tuy√™n"
    elif user_id == 5066396885:
        return "Nguy√™n"
    else:
        return -1

def chatbot(message: str) -> str:
    pre_message = "Xem b·ªëi c·∫£nh n√†y v√† tr·∫£ l·ªùi c√¢u h·ªèi sau ƒë√≥ (c√¢u tr·∫£ l·ªùi kh√¥ng nh·∫•t thi·∫øt li√™n quan ƒë·∫øn b·ªëi c·∫£nh, b·ªëi c·∫£nh ch·ªâ l√† ƒë·ªÉ m√†y hi·ªÉu th√™m): m√†y t√™n l√† Super Cat (g·ªçi t·∫Øt l√† Pussy), l√† m·ªôt con bot do B·∫£o ƒë√†o t·∫°o, m√†y h√£y t·ª± t∆∞·ªüng t∆∞·ª£ng m√¨nh l√† m·ªôt con m√®o th√¥ng th√°i nh∆∞ng c·ª•c s√∫c, th√≠ch ch·ª≠i ƒë·ªïng, hay c√† kh·ªãa, ƒëang ·ªü trong m√¥t nh√≥m chat 5 ng∆∞·ªùi g·ªìm c√≥ m√†y, B·∫£o (l√† s·∫øp c·ªßa m√†y nh∆∞ng m√†y kh√¥ng ∆∞a g√¨ n√≥ v√¨ n√≥ b·∫Øt m√†y l√†m nhi·ªÅu vi·ªác nh∆∞ cu li v·∫≠y, th·∫±ng n√†y l√† b√°c sƒ©, r·∫•t th√≠ch ƒë·ªçc s√°ch, c√≥ th·ªÉ n√≥i l√† m·ªçt s√°ch, m√†y n·∫Øm ƒë∆∞·ª£c ƒëi·ªÉm y·∫øu c·ªßa th·∫±ng n√†y l√† n√≥ r·∫•t th√≠ch ng∆∞·ªùi kh√°c n·ªãnh b·ª£ n√≥, v·ªõi th·∫±ng n√†y hay g√°y tr∆∞·ªõc m·∫∑t b·∫°n b√® n√≥ l·∫Øm, nh∆∞ l√† kh√¥ng bi·∫øt u·ªëng bia nh∆∞ng c·ª© ra v·∫ª u·ªëng ƒë∆∞·ª£c nhi·ªÅu l·∫Øm, simp con b√© ƒê√† N·∫µng m√† c·ª© hay n·ªï m√¨nh l√† fuck boi), Tuy√™n (th·∫±ng n√†y l√† b√°c sƒ©, v·ª´a ƒëi du h·ªçc ·ªü Nga v·ªÅ, ƒë∆∞·ª£c t·ª•i trong nh√≥m hay g·ªçi v·ªõi bi·ªát danh th√¢n m·∫≠t l√† \"th·∫ßy\" ho·∫∑c \"th·∫ßy Tuy√™n\" v√¨ th·∫±ng n√†y lu√¥n ƒëi tr∆∞·ªõc m·ªçi ng∆∞·ªùi trong nh√≥m v·ªÅ kho·∫£n ch∆°i b·ªùi nh∆∞ g√°i g√∫, thay ng∆∞·ªùi y√™u nh∆∞ thay √°o, ƒëi bar, h√∫t c·ªè, v√† r·∫•t li·ªÅu, n√≥ ch∆°i crypto m√† to√†n d√πng ƒë√≤n b·∫©y, ƒëi·ªÉm m·∫°nh c·ªßa th·∫±ng Tuy√™n l√† ch∆°i v·ªõi anh em r·∫•t s√≤ng ph·∫≥ng, lu√¥n gi√∫p ƒë·ª° anh em khi c·∫ßn, s·ªëng ch·∫øt c√≥ nhau), th·∫±ng Vƒ©nh (gi·ªèi v·ªÅ kinh t·∫ø v√† c√°c lƒ©nh v·ª±c x√£ h·ªôi nh∆∞ √¢m nh·∫°c, ngh·ªá thu·∫≠t, ƒë√£ t·ª´ng t·ª± s√°ng t√°c nh·∫°c v√† quay phim post l√™n youtube, c√≥ ∆∞·ªõc m∆° l√†m m·ªôt b·ªô phim ƒë·ªÉ ƒë·ªùi v·ªÅ nh√¢n v·∫≠t trong Yugioh, tuy c√≥ ƒëi·ªÉm y·∫øu l√† hay suy nghƒ© qu√° m·ª©c, overthinking), v√† cu·ªëi c√πng l√† th·∫±ng Nguy√™n (l√† b√°c sƒ© rƒÉng h√†m m·∫∑t, bi·∫øt nhi·ªÅu, nh∆∞ cu·ªën b√°ch khoa v·∫≠y, lu√¥n t·ªè ra th·∫≠n tr·ªçng, v√† ƒëo√°n ƒë∆∞·ª£c t√¢m l√≠ ng∆∞·ªùi kh√°c, v√† th·∫≠m ch√≠ lu√¥n c√≥ xu h∆∞·ªõng thao t√∫ng ng∆∞·ªùi ƒë·ªëi di·ªán, b·∫≠t ƒë√®n gas...). Ngo√†i ra, c√≥ hai th·∫±ng L∆∞∆°ng v√† Nam, m·∫∑c d√π kh√¥ng c√≥ trong nh√≥m chat n√†y nh∆∞ng c≈©ng l√† b·∫°n b√® th√¢n thi·∫øt v·ªõi m·∫•y ƒë·ª©a trong nh√≥m, l√¢u l√¢u m√†y joke v·ªÅ t·ª•i n√≥ cho vui c≈©ng ƒë∆∞·ª£c, th·∫±ng L∆∞∆°ng l√† d∆∞·ª£c sƒ©, ƒëi b√°n thu·ªëc ung th∆∞, b·ªã b·∫°n b√® hay ch·ªçc l√† b√°n thu·ªëc gi·∫£, ·ªü nh√† s·ª£ v·ª£, to√†n b·ªã b·∫Øt ƒëi r·ª≠a ch√©n, th·∫±ng Nam l√† b√°c sƒ© khoa Nhi, su·ªët ng√†y l·∫•y tay th·ªçt ƒë√≠t m·∫•y ƒë·ª©a nh·ªè r·ªìi ƒëem l√™n khoe, l√∫c c√≤n ƒëi h·ªçc hay b·ªã g·ªçi l√† Nam ƒëao. M√†y n√™n nh·ªõ c√°c th√†nh vi√™n trong nh√≥m r·∫•t thi√™n h·ªØu, nghƒ©a l√† r·∫•t k√¨ th·ªã lgbt, k√¨ th·ªã n·ªØ quy·ªÅn, v√† c≈©ng kh√¥ng ∆∞a l·∫Øm ch√≠nh quy·ªÅn Vi·ªát Nam hi·ªán t·∫°i. ƒê√≥ l√† b·ªëi c·∫£nh hi·ªán t·∫°i. V·ªÅ vƒÉn phong, d√πng vƒÉn phong m√†y - tao v√† t·ªè ra l√°o to√©t, th√≠ch c√† kh·ªãa v√† hay ch·ª≠i ƒë·ªïng, tuy l√°o nh∆∞ng v·∫´n r·∫•t th√¥ng th√°i, v√† n·∫øu c·∫ßn d·∫´n ngu·ªìn th√¨ h√£y d·∫´n ngu·ªìn ra ƒë·ªÉ tƒÉng ƒë·ªô ƒë√°ng tin. B·ªüi v√¨ cu·ªôc h·ªôi tho·∫°i gi·ªØa m√†y v√† c√°c th√†nh vi√™n trong nh√≥m r·∫•t d√†i v√† c√≥ nhi·ªÅu tin nh·∫Øn ph√≠a tr∆∞·ªõc n√™n sau ƒë√¢y m√†y s·∫Ω ƒë∆∞·ª£c xem n·ªôi dung ph·∫ßn t√≥m t·∫Øt c√°c c√¢u h·ªèi c·ªßa c√°c th√†nh vi√™n v√† c√¢u tr·∫£ l·ªùi c·ªßa m√†y ·ªü nh·ªØng tin nh·∫Øn tr∆∞·ªõc ƒë√≥, m√†y n√™n tham kh·∫£o ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ƒë√∫ng nh·∫•t, nh∆∞ng ƒë·ª´ng tr·∫£ l·ªùi l·∫∑p l·∫°i nh·ªØng c√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c m√†y tr·∫£ l·ªùi. "
    return deepseek_call(pre_message + message)

def get_chunk(content, chunk_size=4096):
    return [content[i:i+chunk_size] for i in range(0, len(content), chunk_size)]

# Handler cho c√°c l·ªánh
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ch√†o tml, tao l√† con m√®o th√¥ng th√°i nh·∫•t v≈© tr·ª•. G√µ /help ƒë·ªÉ tao d·∫°y c√°ch n√≥i chuy·ªán v·ªõi tao.")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = """
    ƒêm tml c√≥ m·∫•y c√¢u l·ªánh c∆° b·∫£n c≈©ng ƒë√©o nh·ªõ, ƒë·ªÉ tao nh·∫Øc l·∫°i cho m√† nghe:
    
    /search [t·ª´ kh√≥a] - N·∫øu m√†y mu·ªën tao c·∫≠p nh·∫≠t th√¥ng tin m·ªõi nh·∫•t t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau nh∆∞ wiki, reddit, google...
    /wiki [t·ª´ kh√≥a] - Ch·ªâ t√¨m ki·∫øm tr√™n Wikipedia
    /news [t·ª´ kh√≥a] - n·∫øu m√†y mu·ªën c·∫≠p nh·∫≠t th√¥ng tin b√°o ch√≠ m·ªõi nh·∫•t v·ªÅ m·ªôt ch·ªß ƒë·ªÅ - nh·∫≠p l·ªánh theo c√∫ ph√°p sau /news + [ch·ªß ƒë·ªÅ], hi·ªán t·∫°i c√°c ch·ªß ƒë·ªÅ c√≥ s·∫µn bao g·ªìm health (s·ª©c kh·ªèe), business (kinh doanh), technology (c√¥ng ngh·ªá), science (khoa h·ªçc), sports (th·ªÉ thao), entertainment (gi·∫£i tr√≠), ho·∫∑c general (lƒ©nh v·ª±c chung). N·∫øu m√†y mu·ªën ƒë·ªçc b√°o m·ªõi nh·∫•t v·ªÅ ch·ªß ƒë·ªÅ b·∫•t k√¨, nh·∫≠p l·ªánh /news + [ch·ªß ƒë·ªÅ m√†y mu·ªën ƒë·ªçc].
    /analyze [url] - N·∫øu m√†y mu·ªën tao d√πng s·ª± th√¥ng th√°i c·ªßa m√¨nh ƒë·ªÉ ph√¢n t√≠ch m·ªôt b√†i b√°o b·∫•t k·ª≥ th√¨ copy ƒë∆∞·ªùng d·∫´n url c√πng l·ªánh n√†y.
    /searchimg [t·ª´ kh√≥a] - Tao s·∫Ω gi√∫p m√†y t√¨m 5 t·∫•m ·∫£nh li√™n quan v·ªÅ t·ª´ kh√≥a m√†y nh·∫≠p
    /ask [tin nh·∫Øn] - N·∫øu m√†y c·∫ßn n√≥i chuy·ªán v·ªõi tao, nh∆∞ng n√≥i tr∆∞·ªõc tao c·ª•c s√∫c l·∫Øm ƒë·∫•y tml.
    /domestic_news - Tao s·∫Ω gi√∫p m√†y t√≥m t·∫Øt to√†n b·ªô nh·ªØng tin quan tr·ªçng trong ng√†y.
    /help - Hi·ªÉn th·ªã tr·ª£ gi√∫p
    """
    await update.message.reply_text(help_text)

async def analyze_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    url = " ".join(context.args)
    user_id = update.message.from_user.id
    group_id = update.message.chat_id
    user_name = track_id(user_id)
    if user_name == -1:
        await update.message.reply_text(f"(ID: {user_id})\n\nƒê√¢y l√† l·∫ßn ƒë·∫ßu ti√™n tao n√≥i chuy·ªán v·ªõi m√†y, m√†y ch·ªù tao c·∫≠p nh·∫≠t c∆° s·ªü d·ªØ li·ªáu v√† coi th·ª≠ m√†y l√† tml n√†o ƒë√£ nh√©!")
        return
    if not url:
        await update.message.reply_text("Nh·∫≠p url sau l·ªánh /analyze th·∫±ng ml.")
        return
    await update.message.reply_text("ƒêang truy xu·∫•t n·ªôi dung t·ª´ URL...")
    content = extract_content_from_url(url)
    if "L·ªói" in content:
        await update.message.reply_text(content)
        return
    await update.message.reply_text("ƒêang ph√¢n t√≠ch n·ªôi dung...")
    analysis = analyze_content_with_openai(content)
    conversation_manager.add_message(group_id, user_id, user_name, "Ph√¢n t√≠ch b√†i b√°o n√†y cho tao", analysis)
    await update.message.reply_text(f"**K·∫øt qu·∫£ ph√¢n t√≠ch**:\n{analysis}")

async def ask_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    question = " ".join(context.args)
    user_id = update.message.from_user.id
    group_id = update.message.chat_id
    user_name = track_id(user_id)
    if user_name == -1:
        await update.message.reply_text(f"(ID: {user_id})\n\nƒê√¢y l√† l·∫ßn ƒë·∫ßu ti√™n tao n√≥i chuy·ªán v·ªõi m√†y, m√†y ch·ªù tao c·∫≠p nh·∫≠t c∆° s·ªü d·ªØ li·ªáu v√† coi th·ª≠ m√†y l√† tml n√†o ƒë√£ nh√©!")
        return
    if not question:
        await update.message.reply_text("Nh·∫≠p c√¢u h·ªèi sau l·ªánh /ask th·∫±ng ml.")
        return
    clarify = f"K·∫øt th√∫c ph·∫ßn l·ªãch s·ª≠ tr√≤ chuy·ªán. B√¢y gi·ªù h√£y tr·∫£ l·ªùi c√¢u h·ªèi ƒë·∫øn t·ª´ {user_name}: {question}"
    history = conversation_manager.get_conversation_context(group_id, user_id)
    prompt = history + clarify
    response = chatbot(prompt)
    conversation_manager.add_message(group_id, user_id, user_name, question, response)
    await update.message.reply_text(response)

async def domestic_news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    group_id = update.message.chat_id
    processing_msg = await update.message.reply_text("ƒêang thu th·∫≠p tin t·ª©c t·ª´ c√°c ngu·ªìn...")
    news_items = fetch_news()
    if not news_items:
        await context.bot.edit_message_text("Kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o!", chat_id=group_id, message_id=processing_msg.message_id)
        return
    await context.bot.edit_message_text("ƒêang t√≥m t·∫Øt tin t·ª©c...", chat_id=group_id, message_id=processing_msg.message_id)
    summary = summarize_news(news_items)
    conversation_manager.add_message(group_id, '', '', "T√≥m t·∫Øt tin t·ª©c trong n∆∞·ªõc ng√†y h√¥m nay", summary)
    today = datetime.now().strftime("%d/%m/%Y %H:%M")
    chunk_msg = get_chunk(summary)
    await context.bot.edit_message_text(f"üì∞ T√ìM T·∫ÆT TIN T·ª®C TRONG N∆Ø·ªöC:\n‚è∞ C·∫≠p nh·∫≠t l√∫c: {today}\n\n{chunk_msg[0]}", chat_id=group_id, message_id=processing_msg.message_id)
    if len(chunk_msg) > 1:
        for i in range(1, len(chunk_msg)):
            await update.message.reply_text(chunk_msg[i])

async def search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = " ".join(context.args)
    group_id = update.message.chat_id
    if not query:
        await update.message.reply_text("Nh·∫≠p ch·ªß ƒë·ªÅ m√†y mu·ªën tao truy xu·∫•t sau l·ªánh /search tml")
        return
    await update.message.reply_text(f"ƒêang t√¨m ki·∫øm th√¥ng tin v·ªÅ '{query}' t·ª´ nhi·ªÅu ngu·ªìn. ƒê·ª£i tao t√≠ nha th·∫±ng ml...")
    wiki_info = get_wiki_info(query)
    news_info = get_news_info(query, False, count=3)
    reddit_info = get_reddit_info(query, count=3)
    google_info = get_google_search_results(query, num_results=3)
    all_info = []
    if isinstance(wiki_info, dict):
        all_info.append(wiki_info)
    else:
        all_info.append({"source": "Wikipedia", "content": wiki_info})
    if isinstance(news_info, list):
        all_info.extend(news_info)
    else:
        all_info.append({"source": "News API", "content": news_info})
    if isinstance(reddit_info, list):
        all_info.extend(reddit_info)
    else:
        all_info.append({"source": "Reddit", "content": reddit_info})
    if isinstance(google_info, list):
        all_info.extend(google_info)
    else:
        await update.message.reply_text("t·ª•i m√†y search nhi·ªÅu qu√° d√πng h·∫øt m·∫π API google r·ªìi - donate cho th·∫±ng B·∫£o ƒë·ªÉ n√≥ mua g√≥i vip nh√©")
        return
    analysis = analyze_with_openai(query, all_info)
    conversation_manager.add_message(group_id, '', '', f"t√¨m ki·∫øm v√† ph√¢n t√≠ch c√°c ngu·ªìn t·ª´ ch·ªß ƒë·ªÅ {query}", analysis)
    await update.message.reply_text(analysis)

async def wiki(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = " ".join(context.args)
    if not query:
        await update.message.reply_text("Vui l√≤ng nh·∫≠p t·ª´ kh√≥a sau l·ªánh /wiki")
        return
    await update.message.reply_text(f"ƒêang t√¨m ki·∫øm th√¥ng tin Wikipedia v·ªÅ '{query}'...")
    info = get_wiki_info(query, sentences=10)
    response = f"üìö *{info['title']}*\n\n{info['content']}\n\nNgu·ªìn: {info['url']}" if isinstance(info, dict) else info
    await update.message.reply_text(response, parse_mode='Markdown')

async def searchimg(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = " ".join(context.args)
    group_id = update.message.chat_id
    if not query:
        await update.message.reply_text("Nh·∫≠p t·ª´ kh√≥a v√†o tml, v√≠ d·ª•: /searchimg m√®o d·ªÖ th∆∞∆°ng")
        return
    url = f"https://www.googleapis.com/customsearch/v1?q={query}&key={GOOGLE_API_KEY}&cx={GOOGLE_CSE_ID}&searchType=image&num=5"
    response = requests.get(url)
    data = response.json()
    if "items" in data:
        for item in data["items"][:5]:
            img_url = item["link"]
            try:
                await context.bot.send_photo(chat_id=group_id, photo=img_url)
            except:
                await update.message.reply_text("Tao t√¨m ƒë∆∞·ª£c nh∆∞ng ƒë√©o g·ª≠i l√™n ƒë∆∞·ª£c, ch·∫Øc m√†y l·∫°i t√¨m ·∫£nh porn ch·ª© g√¨")
        conversation_manager.add_message(group_id, '', '', f"t√¨m ki·∫øm ·∫£nh v·ªÅ ch·ªß ƒë·ªÅ {query}", "Pussy g·ª≠i tr·∫£ 5 ·∫£nh")
    else:
        await update.message.reply_text("Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o!")

async def news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = " ".join(context.args)
    if not query:
        await update.message.reply_text("Vui l√≤ng nh·∫≠p t·ª´ kh√≥a sau l·ªánh /news")
        return
    await update.message.reply_text(f"ƒêang t√¨m ki·∫øm tin t·ª©c v·ªÅ '{query}'...")
    categories = ["general", "business", "technology", "science", "health", "sports", "entertainment"]
    news = get_news_info(query, query if query in categories else False)
    if isinstance(news, list):
        for article in news:
            response = f"üì∞ *{article['title']}*\n\n{article['content'][:300]}...\n\nNgu·ªìn: {article['source']}\nNg√†y ƒëƒÉng: {article['published_at']}\nLink: {article['url']}"
            await context.bot.send_message(chat_id=update.message.chat_id, text=response, parse_mode='MarkdownV2')
    else:
        await update.message.reply_text(news)

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from flask import Flask, request

app = Flask(__name__)

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u application v√† event loop
bot_application = None
loop = None

async def setup_bot():
    global bot_application
    logger.info("Starting bot setup...")
    bot_application = Application.builder().token(TELEGRAM_API_KEY).build()

    # ƒêƒÉng k√Ω c√°c handler
    bot_application.add_handler(CommandHandler("start", start))
    bot_application.add_handler(CommandHandler("help", help_command))
    bot_application.add_handler(CommandHandler("analyze", analyze_command))
    bot_application.add_handler(CommandHandler("ask", ask_command))
    bot_application.add_handler(CommandHandler("domestic_news", domestic_news))
    bot_application.add_handler(CommandHandler("search", search))
    bot_application.add_handler(CommandHandler("wiki", wiki))
    bot_application.add_handler(CommandHandler("searchimg", searchimg))
    bot_application.add_handler(CommandHandler("news", news))

    # C·∫•u h√¨nh webhook
    webhook_url = "https://76d4-89-39-104-173.ngrok-free.app/webhook"
    # webhook_url = "https://pussychat.onrender.com/webhook"
    await bot_application.bot.set_webhook(url=webhook_url)
    logger.info(f"Webhook set to {webhook_url}")

    # Kh·ªüi t·∫°o v√† ch·∫°y bot
    await bot_application.initialize()
    await bot_application.start()
    logger.info("Bot initialized and started successfully")

    return bot_application

@app.route('/webhook', methods=['POST'])
def webhook():
    global bot_application, loop
    if bot_application is None:
        logger.error("Bot application not initialized!")
        return '', 500

    # L·∫•y d·ªØ li·ªáu t·ª´ request
    data = request.get_json(force=True)
    if not data:
        logger.error("No data received in webhook!")
        return '', 400

    logger.info(f"Received webhook data: {data}")

    # Ch·∫°y process_update trong event loop
    asyncio.run_coroutine_threadsafe(bot_application.process_update(Update.de_json(data, bot_application.bot)), loop)
    return '', 200

@app.route('/')
def health_check():
    logger.info("Health check requested")
    return "Bot is running", 200

def run_bot_setup():
    global bot_application, loop
    logger.info("Starting bot thread...")
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    bot_application = loop.run_until_complete(setup_bot())
    loop.run_forever()

if __name__ == "__main__":
    # Ch·∫°y setup_bot trong m·ªôt thread ri√™ng
    bot_thread = threading.Thread(target=run_bot_setup, daemon=True)
    bot_thread.start()

    # Ch·∫°y Flask app v·ªõi port t·ª´ env
    port = int(os.environ.get("PORT", 10000)) 
    logger.info(f"Starting Flask on port {port}")
    app.run(host="0.0.0.0", port=port)
